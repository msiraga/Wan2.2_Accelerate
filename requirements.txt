# Core PyTorch (MUST be installed first)
torch>=2.4.0
torchvision>=0.19.0
numpy>=1.23.5,<2

# Diffusion & Transformers (required)
diffusers>=0.31.0
transformers>=4.49.0,<=4.51.3
tokenizers>=0.20.3
accelerate>=1.1.1

# Flash Attention 3 (critical for optimization on H100/H200 GPUs)
# NOTE: Requires torch to be installed first! See INSTALL_INSTRUCTIONS.md
# For H100/H200 (Hopper architecture), install from hopper directory for FA3 support
# Install manually: see commands below
#flash-attn

# Image & Video Processing (required for T2V)
imageio[ffmpeg]
pillow>=9.0.0
einops

# Text Processing (required)
ftfy
regex

# Utilities (required)
easydict
tqdm

# Model Loading (required)
safetensors>=0.4.0

#decord is required for video reading in s2v. 
decord

easydict

#cd /tmp && git clone https://github.com/Dao-AILab/flash-attention.git && cd flash-attention/hopper && pip install -e . --no-build-isolation